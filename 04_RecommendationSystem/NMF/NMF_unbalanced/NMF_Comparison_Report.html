
    <html>
    <head>
        <title>Comparación de Modelos NMF</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background-color: #f8f9fa; }
            h1, h2, h3 { color: #333; }
            table { width: 100%; border-collapse: collapse; margin-top: 20px; background: white; }
            th, td { border: 1px solid #ddd; padding: 10px; text-align: left; }
            th { background-color: #007bff; color: white; }
            tr:nth-child(even) { background-color: #f2f2f2; }
            .conclusion { margin-top: 20px; padding: 15px; background: white; }
        </style>
    </head>
    <body>
        <h1>Comparación de Modelos NMF</h1>
        <p>Este reporte compara dos modelos de descomposición en valores no negativos (NMF), evaluando métricas clave.</p>
        
        <h2>Descripción del Sistema de Recomendación</h2>
        <p>Este sistema de recomendación utiliza <strong>NMF</strong> para factorizar la matriz usuario-producto en representaciones latentes.</p>
        
        <h3>1. Carga y Preprocesamiento de Datos</h3>
        <p>Se construye la matriz de interacciones usuario-producto a partir de datos de compras.</p>
        
        <h3>2. Entrenamiento del Modelo NMF</h3>
        <p>Se comparan dos configuraciones:</p>
        <ul>
            <li><strong>NMF (Baseline):</strong> 50 componentes, inicialización aleatoria.</li>
            <li><strong>NMF2 (Optimized):</strong> 100 componentes, inicialización avanzada, solver 'mu'.</li>
        </ul>
        
        <h2>Métricas de Evaluación</h2>
        <table>
            <tr>
                <th>Métrica</th>
                <th>NMF (Baseline)</th>
                <th>NMF2 (Optimized)</th>
            </tr>
            <tr>
                <td>RMSE</td>
                <td>0.0652</td>
                <td>0.0291</td>
            </tr>
            <tr>
                <td>Precision@5</td>
                <td>0.6669</td>
                <td>0.7055</td>
            </tr>
            <tr>
                <td>Recall@5</td>
                <td>0.7838</td>
                <td>0.8551</td>
            </tr>
            <tr>
                <td><strong>F1-score</strong></td>
                <td><strong>0.7207</strong></td>
                <td><strong>0.7731</strong></td>
            </tr>
            <tr>
                <td>Tiempo de Entrenamiento (s)</td>
                <td>6.32</td>
                <td>11.48</td>
            </tr>
        </table>

        <h2>Conclusiones</h2>
        <div class="conclusion">
            <p><strong>1 - Mejora en Precision y Recall:</strong><br>
            El modelo optimizado superó al baseline tanto en precisión como en recall, alcanzando valores de 70.55% y 85.51% respectivamente. Esto indica que el sistema recomienda con mayor relevancia los productos que los usuarios realmente compran.</p>

            <p><strong>2 - Reducción significativa del RMSE:</strong><br>
            El RMSE bajó de 0.0652 a 0.0291, lo que representa una mejora notable en la capacidad del modelo para predecir correctamente.</p>

            <p><strong>3 - Incremento en el F1-score:</strong><br>
            El F1-score del modelo optimizado fue de 0.7731 frente a 0.7207 del modelo base, lo que refleja un mejor balance entre precisión y recall.</p>

            <p><strong>4 - Costo computacional mayor pero aceptable:</strong><br>
            El tiempo de entrenamiento del modelo optimizado fue mayor (11.48 segundos frente a 6.32), pero sigue siendo razonable dada la mejora en rendimiento.</p>
        </div>
    </body>
    </html>
    