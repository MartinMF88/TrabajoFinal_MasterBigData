
    <html>
    <head>
        <title>Comparación de Modelos NMF</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background-color: #f8f9fa; }
            h1, h2, h3 { color: #333; }
            table { width: 100%; border-collapse: collapse; margin-top: 20px; background: white; }
            th, td { border: 1px solid #ddd; padding: 10px; text-align: left; }
            th { background-color: #007bff; color: white; }
            tr:nth-child(even) { background-color: #f2f2f2; }
            .conclusion { margin-top: 20px; padding: 15px; background: white; }
        </style>
    </head>
    <body>
        <h1>Comparación de Modelos NMF</h1>
        <p>Este reporte compara dos modelos de descomposición en valores no negativos (NMF), evaluando métricas clave.</p>
        
        <h2>Descripción del Sistema de Recomendación</h2>
        <p>Este sistema de recomendación utiliza <strong>NMF</strong> para factorizar la matriz usuario-producto en representaciones latentes.</p>
        
        <h3>1. Carga y Preprocesamiento de Datos</h3>
        <p>Se construye la matriz de interacciones usuario-producto a partir de datos de compras.</p>
        
        <h3>2. Entrenamiento del Modelo NMF</h3>
        <p>Se comparan dos configuraciones:</p>
        <ul>
            <li><strong>NMF (Baseline):</strong> 50 componentes, inicialización aleatoria.</li>
            <li><strong>NMF2 (Optimized):</strong> 100 componentes, inicialización avanzada, solver 'mu'.</li>
        </ul>
        
        <h2>Métricas de Evaluación</h2>
        <table>
            <tr>
                <th>Métrica</th>
                <th>NMF (Baseline)</th>
                <th>NMF2 (Optimized)</th>
            </tr>
            <tr>
                <td>RMSE</td>
                <td>0.0820</td>
                <td>0.0457</td>
            </tr>
            <tr>
                <td>Precision@5</td>
                <td>0.4062</td>
                <td>0.5197</td>
            </tr>
            <tr>
                <td>Recall@5</td>
                <td>0.6839</td>
                <td>0.9280</td>
            </tr>
            <tr>
                <td><strong>F1-score</strong></td>
                <td><strong>0.5096</strong></td>
                <td><strong>0.6663</strong></td>
            </tr>
            <tr>
                <td>Tiempo de Entrenamiento (s)</td>
                <td>67.29</td>
                <td>26.91</td>
            </tr>
        </table>

        <h2>Conclusiones</h2>
        <div class="conclusion">
            <p><strong>1 - Mejora notable en Precision y Recall:</strong><br>
            El modelo optimizado superó ampliamente al baseline, con una precisión del 51.97% y un recall del 92.80%, lo que indica que no solo recomienda mejor, sino que también recomienda más productos relevantes para los usuarios.</p>

            <p><strong>2 - Reducción significativa del RMSE:</strong><br>
            El RMSE se redujo de 0.0820 a 0.0457, lo que representa una mejora superior al 44% en la capacidad del modelo para predecir correctamente.</p>

            <p><strong>3 - Mayor equilibrio entre precisión y cobertura (F1-score):</strong><br>
            El F1-score del modelo optimizado fue 0.6663 frente a 0.5096 en el baseline, reflejando un mejor balance entre acierto y cobertura en las recomendaciones.</p>

            <p><strong>4 - Reducción del tiempo de entrenamiento:</strong><br>
            A pesar de ser un modelo más preciso y complejo, el tiempo de entrenamiento se redujo a 26.91 segundos frente a los 67.29 del baseline, posiblemente por una mejor elección de hiperparámetros.</p>
        </div>
    </body>
    </html>
    